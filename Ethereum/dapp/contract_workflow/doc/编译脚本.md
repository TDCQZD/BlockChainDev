# 编译脚本
智能合约的编译是对合约进行部署和测试的前置步骤，编译步骤的目标是把源代码转成 ABI 和 Bytecode，并且能够处理编译时抛出的错误，确保不会在包含错误的源代码上进行编译。

之前的编译方式是用solc工具做命令行编译，这个过程中牵涉到大段内容的复制粘贴，很容易出错；之后在项目中引入solc模块，可以在node命令行中自动编译并读取结果内容。

现在我们通过脚本来完成自动化编译。

## 目录结构
```
mkdir contract_workflow
cd contract_workflow

mkdir contracts
mkdir scripts
mkdir compiled
mkdir tests

```
目录结构如下：
- contracts 目录存放合约源代码；
- scripts 目录存放编译脚本；
- complied 目录存放编译结果；
- tests 目录存放测试文件。

![编译脚本目录结构](../../images/compiled.png)


## 环境配置

在scripts目录下配置：

``` 
npm init 
npm install solc --save-dev
npm install fs-extra --save-dev
```
## 准备合约源码 

示例中编译Car.sol并放到 contracts 目录下

## 编译脚本-compile.js
在 scripts 目录下新建文件 compile.js并编译。
```
const fs = require('fs'); 
const path = require('path'); 
const solc = require('solc'); 
const contractPath = path.resolve(__dirname, '../contracts', 'Car.sol'); 
const contractSource = fs.readFileSync(contractPath, 'utf8'); 
const result = solc.compile(contractSource, 1); 
console.log(result);

```

我们把合约源码从文件中读出来，然后传给solc编译器，等待同步编译完成之后，把编译结果输出到控制台。

其中solc.compile() 的第二个参数给1，表示启用solc的编译优化器。

编译结果是一个嵌套的js对象，其中可以看到contracts属性包含了所有找到的合约（当然，我们的源码中只有一个Car）。每个合约下面包含了assembly、bytecode、interface、metadata、opcodes 等字段，我们最关心的当然是这两个：
- bytecode：字节码，部署合约到以太坊区块链上时需要使用；
- interface： 二进制应用接口（ABI），使用 web3 初始化智能合约交互实例的时候需要使用。

其中 interface 是被 JSON.stringify 过的字符串，我们用JSON.parse反解出来并格式化，就可以拿到合约的abi对象。


## 保存编译结果
现在将合约部署到区块链上。为此，你必须先通过传入 abi 定义来创建一个合约对象Contract(示例为result.contracts)。然后用这个对象在链上部署并初始化合约。为了方便后续的部署和测试过程直接使用编译结果，需要把编译结果保存到文件系统中，在做改动之前，我们引入一个非常好用的小工具 fs-extra，在脚本中使用 fs-extra 直接替换到 fs，然后在脚本中加入以下代码：
```
Object.keys(result.contracts).forEach( name => {
	const contractName = name.replace(/^:/, '');
	const filePath = path.resolve(__dirname, '../compiled', 
				`${contractName}.json`);
	fs.outputJsonSync(filePath, result.contracts[name]);
	console.log(`save compiled contract ${contractName} to 
			${filePath}`);
});

```
然后重新运行编译脚本，确保 complied 目录下包含了新生成的 Car.json。

类似于前端构建流程中的编译步骤，我们编译前通常需要把之前的结果清空，然后把最新的编译结果保存下来，这对保障一致性非常重要。所以继续对编译脚本做如下改动：
在脚本执行的开始加入清除编译结果的代码：
```
// cleanup
const compiledDir = path.resolve(__dirname, '../compiled');
fs.removeSync(compiledDir);
fs.ensureDirSync(compiledDir);

```
这里专门定义了compiledDir，所以后面的filePath也可以改为：
```
const filePath = 
	path.resolve(compiledDir, `${contractName}.json`);
```
新增的 cleanup 代码段的作用就是准备全新的目录，修改完之后，需要重新运行编译脚本，确保一切正常。


## 处理编译错误
现在的编译脚本只处理了最常见的情况，即 Solidity 源代码没问题，这个假设其实是不成立的。如果源代码有问题，我们在编译阶段就应该报出来，而不应该把错误的结果写入到文件系统，因为这样会导致后续步骤失败。 为了搞清楚编译器 solc 遇到错误时的行为，我们人为在源代码中引入错误（例如把 function 关键字写成 functio），看看脚本的表现如何。
重新运行编译脚本，发现它并没有报错，而是把错误作为输出内容打印出来，其中错误的可读性比较差。
所以我们对编译脚本稍作改动，在编译完成之后就检查error，让它能够在出错时直接抛出错误：
```
// check errors
if (Array.isArray(result.errors) && result.errors.length) {
	throw new Error(result.errors[0]);
}
```
重新运行编译脚本，可以看到我们得到了可读性更好的错误提示。
## 运行脚本编译合约
```
node compile.js
```
## 最终版编译脚本
```
const fs = require('fs-extra'); 
const path = require('path'); 
const solc = require('solc'); 

// cleanup 
const compiledDir = path.resolve(__dirname, '../compiled');
fs.removeSync(compiledDir); 
fs.ensureDirSync(compiledDir); 

// compile const contractPath = path.resolve(__dirname, 
				'../contracts', 'Car.sol'); 
const contractSource = fs.readFileSync(contractPath, 'utf8'); 
const result = solc.compile(contractSource, 1); 

// check errors 
if (Array.isArray(result.errors) && result.errors.length) {
	throw new Error(result.errors[0]); 
}

// save to disk 
Object.keys(result.contracts).forEach(name => { 
const contractName = name.replace(/^:/, ''); 
const filePath = path.resolve(compiledDir, 
				`${contractName}.json`); 
fs.outputJsonSync(filePath, result.contracts[name]); 
console.log(`save compiled contract ${contractName} to 
		${filePath}`); });	

```